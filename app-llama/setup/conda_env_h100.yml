name: llama-h100
channels:
  - pytorch
  - nvidia
  - conda-forge
  - huggingface
dependencies:
  # Python
  - python=3.10
  
  # PyTorch with CUDA 11.8 for H100 (more stable than 12.1)
  - pytorch>=2.0.0
  - torchvision
  - torchaudio
  - pytorch-cuda=11.8
  
  # CUDA toolkit and drivers
  - cuda-toolkit=11.8
  
  # Core ML/AI packages
  - numpy>=1.21.0
  - scipy
  - scikit-learn
  - pandas
  
  # Hugging Face ecosystem
  - transformers>=4.30.0
  - tokenizers>=0.13.0
  - datasets
  - accelerate>=0.20.0
  - huggingface_hub
  
  # Performance packages
  - bitsandbytes  # For quantization
  
  # Development and monitoring
  - ipython
  - jupyter
  - matplotlib
  - seaborn
  - tqdm
  - psutil
  - gpustat
  
  # Additional utilities
  - requests
  - urllib3
  - certifi
  
  - pip
  
  - pip:
    # Latest versions via pip for cutting-edge features
    - torch>=2.0.0
    - transformers>=4.30.0
    - accelerate>=0.20.0
    - optimum>=1.12.0
    - safetensors
    
    # NVIDIA-specific optimizations
    - nvidia-ml-py
    - pynvml
    
    # Development tools
    - pytest
    - black
    - flake8
    
    # Optional: Advanced features (install manually if needed)
    # - flash-attn  # Commented out due to dependency conflicts
    # - deepspeed   # Commented out - install manually if needed
    # - xformers    # Commented out - install manually if needed
