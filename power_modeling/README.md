# Power Modeling Framework

This directory contains the complete power modeling framework extracted and modernized from the FGCS 2023 paper implementation. The framework provides comprehensive tools for GPU power prediction, EDP optimization, and energy-efficient frequency selection.

## ğŸš€ Quick Start

### Simple Analysis
```python
from power_modeling import analyze_application

# Quick analysis of an application
results = analyze_application(
    profiling_file="data/app_profiling.csv",
    app_name="MyApplication",
    gpu_type="V100"
)

print(f"Optimal frequency: {results['summary']['optimal_frequency']}")
print(f"Energy savings: {results['summary']['energy_savings']}")
```

### Full Framework Usage
```python
from power_modeling import FGCSPowerModelingFramework
import pandas as pd

# Initialize framework
framework = FGCSPowerModelingFramework(
    model_types=['fgcs_original', 'polynomial_deg2', 'random_forest_enhanced'],
    gpu_type='V100'
)

# Load and analyze data
results = framework.analyze_from_file(
    profiling_file="data/profiling.csv",
    performance_file="data/performance.csv",
    app_name="MyApp"
)

# Save results
framework.save_results(results, output_dir="results/")
```

## ğŸ“Š Model Types

### 1. FGCS Original Model
- **Description**: Exact implementation from FGCS 2023 paper
- **Features**: FP operations, DRAM activity, SM clock frequency
- **Use Case**: Reproduction of original paper results

### 2. Polynomial Models
- **Description**: Polynomial regression with configurable degree
- **Features**: Polynomial expansion of input features
- **Use Case**: Simple, interpretable power prediction

### 3. Enhanced Random Forest
- **Description**: Tuned Random Forest with feature engineering
- **Features**: Ensemble of decision trees with optimized hyperparameters
- **Use Case**: High accuracy with feature importance analysis

### 4. XGBoost Model
- **Description**: Gradient boosting with advanced regularization
- **Features**: GPU-accelerated training, automatic feature selection
- **Use Case**: Maximum prediction accuracy for complex patterns

## ğŸ”§ Training Custom Models

```python
import pandas as pd
from power_modeling import FGCSPowerModelingFramework

# Prepare training data
training_data = pd.DataFrame({
    'fp_activity': [0.1, 0.2, 0.3, 0.4, 0.5],
    'dram_activity': [0.05, 0.1, 0.15, 0.2, 0.25],
    'sm_clock': [1000, 1100, 1200, 1300, 1400],
    'power': [150, 180, 210, 240, 270]
})

# Train models
framework = FGCSPowerModelingFramework()
training_results = framework.train_models(
    training_data, 
    target_column='power',
    test_size=0.2
)

print(f"Best model: {training_results['best_model'][0]}")
print(f"RÂ² score: {training_results['best_model'][1]:.4f}")
```

## ğŸ“ˆ Power Prediction

```python
# Predict power across frequency range
power_sweep = framework.predict_power_sweep(
    fp_activity=0.3,
    dram_activity=0.15,
    frequencies=[800, 900, 1000, 1100, 1200]
)

print(power_sweep)
```

## âš¡ EDP Optimization

```python
# Optimize application for energy-delay product
optimization_results = framework.optimize_application(
    fp_activity=0.3,
    dram_activity=0.15,
    baseline_runtime=1.0,
    app_name="MyApp"
)

print(f"EDP optimal frequency: {optimization_results['edp_optimal']['frequency']}")
print(f"EDÂ²P optimal frequency: {optimization_results['ed2p_optimal']['frequency']}")
```

## ğŸ¯ GPU Support

### Supported GPUs
- **V100**: Tesla V100 (default)
- **A100**: A100 series
- **H100**: H100 series

### Frequency Ranges
- **V100**: 405-1380 MHz (7 MHz steps)
- **A100**: 210-1410 MHz (predefined frequencies)
- **H100**: 210-1980 MHz (17 MHz steps)

## ğŸ“ File Structure

```
power_modeling/
â”œâ”€â”€ __init__.py                    # Main exports
â”œâ”€â”€ fgcs_integration.py           # High-level framework interface
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ fgcs_models.py           # FGCS and polynomial models
â”‚   â”œâ”€â”€ ensemble_models.py       # Random Forest, XGBoost models
â”‚   â””â”€â”€ model_factory.py         # Model factory and pipeline
â”œâ”€â”€ feature_engineering/
â”‚   â””â”€â”€ preprocessing.py         # Data preprocessing utilities
â””â”€â”€ validation/
    â””â”€â”€ model_validation.py      # Model validation utilities
```

## ğŸ” Data Format

### Profiling Data Format
```csv
app_name,fp_activity,dram_activity,sm_clock,power
MyApp,0.25,0.12,1000,165.5
MyApp,0.25,0.12,1100,182.3
MyApp,0.25,0.12,1200,198.7
```

### Performance Data Format
```csv
app_name,frequency,runtime,throughput
MyApp,1000,1.25,800
MyApp,1100,1.15,850
MyApp,1200,1.08,900
```

## ğŸ“Š Output Analysis

### Optimization Results
```python
{
    'edp_optimal': {
        'frequency': 1050,
        'power': 175.2,
        'runtime': 1.12,
        'edp': 196.224
    },
    'ed2p_optimal': {
        'frequency': 950,
        'power': 158.3,
        'runtime': 1.18,
        'ed2p': 220.175
    },
    'recommendations': {
        'primary_recommendation': {
            'frequency': 1050,
            'expected_energy_savings': '12.5%',
            'expected_performance_impact': '8.0%',
            'reason': 'Optimal EDP trade-off'
        }
    }
}
```

## ğŸ§ª Validation and Testing

The framework includes comprehensive validation:
- Cross-validation for model training
- Performance metrics calculation
- Statistical significance testing
- Model comparison and selection

## ğŸ”¬ Research Extensions

The framework is designed for extensibility:
- Custom model integration
- Additional optimization metrics
- Multi-objective optimization
- Uncertainty quantification

## ğŸ“š References

1. FGCS 2023 Paper: "Energy-Efficient GPU Frequency Selection for Deep Learning Inference"
2. Original `gpupowermodel` implementation
3. Enhanced methodology for modern AI workloads

## ğŸ¤ Contributing

To add new models or features:
1. Implement model in appropriate module
2. Add to `model_factory.py`
3. Update `fgcs_integration.py` if needed
4. Add tests in `validation/`
5. Update documentation

## ğŸ“„ License

This framework is part of the AI Inference Energy project by Mert Side.
